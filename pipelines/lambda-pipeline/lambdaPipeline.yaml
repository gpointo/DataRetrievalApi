AWSTemplateFormatVersion: '2010-09-09'
Description: Deploy Lambda code into S3 buckets

Parameters:    
  codeBuildName:
    Type: String
    Default: dataRetrievalApiBuild
    Description: A name for the CodeBuild Job
  GitHubOwner:
    Type: String
    AllowedPattern: "[A-Za-z0-9-]+"
    Description: The Owner of the GitHub Repo
    Default: gpointo
  GitHubRepo:
    Type: String
    Description: The name of the GitHub Repo
    Default: DataRetrievalApi
  GitHubBranch:
    Type: String
    AllowedPattern: "[A-Za-z0-9-]+"
    Description: The name of the GitHub Repo Branch which should be used
    Default: main
  TargetS3BucketName:
    Type: String
    AllowedPattern: "[A-Za-z0-9-]+"
    Description: The name of the S3 bucket where the artifact will be stored
    Default: retreivedata-landing-lambda
  PipelineArtifactsBucket:
    Type: String
    AllowedPattern: "[A-Za-z0-9-]+"
    Description: The name of the S3 bucket where the artifact will be stored
    Default: codepipeline-us-east-1-785665804025
Resources:
  TargetS3Bucket:
    Type: AWS::S3::Bucket
    DeletionPolicy: Delete
    Properties:
      BucketName: !Ref TargetS3BucketName
  CodeBuildProject:
    Type: AWS::CodeBuild::Project
    Properties:
      ServiceRole: arn:aws:iam::841688515269:role/service-role/codebuild-DataRetreivalBuild-service-role
      Name: !Ref codeBuildName
      Artifacts:
        Type: CODEPIPELINE
      Environment:
        Type: LINUX_CONTAINER
        ComputeType: BUILD_GENERAL1_SMALL
        Image: aws/codebuild/standard:4.0
        PrivilegedMode: True
      Source:
        Type: CODEPIPELINE
        BuildSpec: |
          version: 0.2
          phases:
            build:
              commands:
                - mkdir deploy
                - cp -a dataload-batch-state-machines/src/* deploy/
                - cp -a dataload-batch-configs/* deploy/
                - cp -a check-dataload-batch-status-lambda/src/*  deploy/
                - cd deploy
                - zip -r check-dataload-batch-status.zip check-dataload-batch-status.py requirements.txt
                - aws s3 cp check-dataload-batch-status.zip s3://retreivedata-landing-lambda
                - rm check-dataload-batch-status.py requirements.txt
                - cd ../
                - aws lambda update-function-code --function-name acs-check-dataload-batch-status --s3-bucket retreivedata-landing-lambda --s3-key check-dataload-batch-status.zip
                - cp -a command-lambda/src/*  deploy/
                - cd deploy
                - zip command-lambda.zip command-lambda.py requirements.txt
                - aws s3 cp command-lambda.zip s3://retreivedata-landing-lambda
                - rm command-lambda.py requirements.txt
                - cd ../
                - aws lambda update-function-code --function-name command-lambda --s3-bucket retreivedata-landing-lambda --s3-key command-lambda.zip
                - cp -a schedule-state-machine-lambda/src/* deploy/
                - cd deploy
                - zip acs-schedule-state-machine.zip acs-schedule-state-machine.py requirements.txt
                - aws s3 cp acs-schedule-state-machine.zip s3://retreivedata-landing-lambda
                - aws lambda update-function-code --function-name acs-schedule-state-machine --s3-bucket retreivedata-landing-lambda --s3-key acs-schedule-state-machine.zip
                - rm acs-schedule-state-machine.py requirements.txt
                - cd ../
                - cp -a acs-start-dataload-batch-lambda/src/acs-start-dataload-batch-lambda.py deploy/
                - cd deploy
                - zip acs-start-dataload-batch-lambda.zip acs-start-dataload-batch-lambda.py 
                - rm acs-start-dataload-batch-lambda.py
                - aws s3 cp acs-start-dataload-batch-lambda.zip s3://retreivedata-landing-lambda
                - aws lambda update-function-code --function-name acs-start-dataload-batch-lambda --s3-bucket retreivedata-landing-lambda --s3-key acs-start-dataload-batch-lambda.zip
          artifacts:
            files:
              - '**/*'
            base-directory: "deploy*"
            discard-paths: yes
  CodePipeline:
    Type: AWS::CodePipeline::Pipeline
    Properties:
      Name: DataRetrievalpipe
      ArtifactStore:
        Type: S3
        Location: !Ref PipelineArtifactsBucket
      RestartExecutionOnUpdate: true
      RoleArn: arn:aws:iam::841688515269:role/service-role/AWSCodePipelineServiceRole-us-east-1-acs-project-pipeline
      Stages:
        - Name: Source
          Actions:
            - Name: Source
              InputArtifacts: []
              ActionTypeId:
                Category: Source
                Owner: ThirdParty
                Version: '1'
                Provider: GitHub
              OutputArtifacts:
                - Name: SourceArtifact  
              Configuration:
                Owner: !Ref GitHubOwner
                Repo: !Ref GitHubRepo
                Branch: !Ref GitHubBranch
                PollForSourceChanges: false
                OAuthToken: "{{resolve:secretsmanager:acs/github/token:SecretString:GITHUB_PERSONAL_TOKEN}}"
              RunOrder: 1
        - Name: Build
          Actions:
            - Name: CodeBuild
              ActionTypeId:
                Category: Build
                Owner: AWS
                Provider: CodeBuild
                Version: '1'
              InputArtifacts:
                - Name: SourceArtifact
              OutputArtifacts:
                - Name: BuildArt
              Configuration:
                ProjectName: !Ref CodeBuildProject
              RunOrder: 1
  GithubWebhook:
    Type: 'AWS::CodePipeline::Webhook'
    Properties:
      Authentication: GITHUB_HMAC
      AuthenticationConfiguration:
        SecretToken: "{{resolve:secretsmanager:acs/github/token:SecretString:GITHUB_PERSONAL_TOKEN}}"
      RegisterWithThirdParty: true
      Filters:
        - JsonPath: "$.ref"
          MatchEquals: refs/heads/{Branch}
      TargetPipeline: !Ref CodePipeline
      TargetAction: Source
      TargetPipelineVersion: !GetAtt CodePipeline.Version
  
 
